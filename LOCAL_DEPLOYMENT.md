# æœ¬åœ°åŒ–éƒ¨ç½²æŒ‡å—

## ç¡¬ä»¶è¦æ±‚

### æ¨èé…ç½®
- **CPU**: 8æ ¸ä»¥ä¸Š
- **å†…å­˜**: 16GB+
- **å­˜å‚¨**: 10GB+ å¯ç”¨ç©ºé—´
- **GPU**: å¯é€‰ï¼Œ8GB+ æ˜¾å­˜ç”¨äºLLMåŠ é€Ÿ

### æœ€ä½é…ç½®
- **CPU**: 4æ ¸
- **å†…å­˜**: 8GB
- **å­˜å‚¨**: 5GB+ å¯ç”¨ç©ºé—´

## æœ¬åœ°LLMéƒ¨ç½²

### æ–¹æ¡ˆ1: Ollama (æ¨è)

```bash
# å®‰è£…Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# ä¸‹è½½ä¸­æ–‡æ¨¡å‹
ollama pull qwen2.5:1.5b
ollama pull qwen2.5:7b  # å¯é€‰ï¼Œæ›´å¥½æ•ˆæœä½†éœ€æ›´å¤šå†…å­˜

# å¯åŠ¨æœåŠ¡
ollama serve
```

### æ–¹æ¡ˆ2: LM Studio

1. ä¸‹è½½ [LM Studio](https://lmstudio.ai/)
2. æœç´¢å¹¶ä¸‹è½½ä¸­æ–‡æ¨¡å‹ï¼š
   - `Qwen2.5-1.5B-Instruct-GGUF`
   - `BGE-small-zh` (Embeddingæ¨¡å‹)
3. å¯åŠ¨æœ¬åœ°æœåŠ¡å™¨ (é»˜è®¤ç«¯å£1234)

## å‘é‡æ¨¡å‹éƒ¨ç½²

### ä¸­æ–‡Embeddingæ¨¡å‹

```python
# è‡ªåŠ¨ä¸‹è½½ä¸­æ–‡ä¼˜åŒ–æ¨¡å‹
from sentence_transformers import SentenceTransformer

# æ–¹æ¡ˆ1: é€šç”¨ä¸­æ–‡æ¨¡å‹
model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')

# æ–¹æ¡ˆ2: ä¸“é—¨ä¸­æ–‡æ¨¡å‹ (æ¨è)
model = SentenceTransformer('shibing624/text2vec-base-chinese')

# æ–¹æ¡ˆ3: BGEä¸­æ–‡æ¨¡å‹ (æœ€ä½³æ•ˆæœ)
model = SentenceTransformer('BAAI/bge-small-zh-v1.5')
```

### ç¦»çº¿æ¨¡å‹éƒ¨ç½²

```bash
# é¢„ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°
mkdir -p models/
cd models/

# ä¸‹è½½ä¸­æ–‡Embeddingæ¨¡å‹
git clone https://huggingface.co/BAAI/bge-small-zh-v1.5

# åœ¨ä»£ç ä¸­ä½¿ç”¨æœ¬åœ°è·¯å¾„
model = SentenceTransformer('./models/bge-small-zh-v1.5')
```

## æ•°æ®åº“é…ç½®

### SQLite (é»˜è®¤)
- æ— éœ€é¢å¤–å®‰è£…
- é€‚åˆä¸­å°å‹æ•°æ®
- æ–‡ä»¶å­˜å‚¨ï¼Œä¾¿äºå¤‡ä»½

### PostgreSQL (å¯é€‰)
```bash
# Ubuntu/Debian
sudo apt install postgresql postgresql-contrib

# åˆ›å»ºæ•°æ®åº“
sudo -u postgres createdb cherry_context

# é…ç½®è¿æ¥
export DATABASE_URL="postgresql://user:password@localhost/cherry_context"
```

### Neo4j (å›¾æ•°æ®åº“ï¼Œå¯é€‰)
```bash
# ä¸‹è½½Neo4j Community Edition
wget -O - https://debian.neo4j.com/neotechnology.gpg.key | sudo apt-key add -
echo 'deb https://debian.neo4j.com stable 4.4' | sudo tee /etc/apt/sources.list.d/neo4j.list
sudo apt update
sudo apt install neo4j

# å¯åŠ¨æœåŠ¡
sudo systemctl start neo4j
# è®¿é—® http://localhost:7474
```

## å®Œæ•´éƒ¨ç½²è„šæœ¬

### ä¸€é”®éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy_local.sh

echo "ğŸ’ Cherry Context Plugin æœ¬åœ°åŒ–éƒ¨ç½²"

# 1. æ£€æŸ¥Pythonç¯å¢ƒ
python3 --version || { echo "è¯·å…ˆå®‰è£…Python 3.8+"; exit 1; }

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv cherry_env
source cherry_env/bin/activate

# 3. å®‰è£…ä¾èµ–
pip install -r requirements_mcp.txt

# 4. å®‰è£…Ollama
if ! command -v ollama &> /dev/null; then
    echo "å®‰è£…Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
fi

# 5. ä¸‹è½½æ¨¡å‹
echo "ä¸‹è½½ä¸­æ–‡LLMæ¨¡å‹..."
ollama pull qwen2.5:1.5b

# 6. å¯åŠ¨OllamaæœåŠ¡
ollama serve &
sleep 5

# 7. åˆå§‹åŒ–æ’ä»¶
python -c "from cherry_plugin.plugin import CherryContextPlugin; CherryContextPlugin()"

echo "âœ… éƒ¨ç½²å®Œæˆï¼"
echo "OllamaæœåŠ¡: http://localhost:11434"
echo "è¯·é…ç½®Cherry Studio MCPè®¾ç½®"
```

### Windowséƒ¨ç½²è„šæœ¬

```batch
@echo off
REM deploy_local.bat

echo ğŸ’ Cherry Context Plugin æœ¬åœ°åŒ–éƒ¨ç½²

REM 1. æ£€æŸ¥Python
python --version >nul 2>&1 || (
    echo è¯·å…ˆå®‰è£…Python 3.8+
    exit /b 1
)

REM 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv cherry_env
call cherry_env\Scripts\activate

REM 3. å®‰è£…ä¾èµ–
pip install -r requirements_mcp.txt

REM 4. ä¸‹è½½LM Studio (æ‰‹åŠ¨)
echo è¯·æ‰‹åŠ¨ä¸‹è½½å¹¶å®‰è£…LM Studio: https://lmstudio.ai/

REM 5. åˆå§‹åŒ–æ’ä»¶
python -c "from cherry_plugin.plugin import CherryContextPlugin; CherryContextPlugin()"

echo âœ… éƒ¨ç½²å®Œæˆï¼
pause
```

## é…ç½®ä¼˜åŒ–

### å†…å­˜ä¼˜åŒ–é…ç½®

```python
# cherry_plugin/config.json
{
  "settings": {
    "vector_search_k": 3,        # å‡å°‘æ£€ç´¢æ•°é‡
    "cache_expire_hours": 48,    # å»¶é•¿ç¼“å­˜æ—¶é—´
    "prompt_max_length": 2000,   # é™åˆ¶prompté•¿åº¦
    "batch_size": 16             # æ‰¹å¤„ç†å¤§å°
  },
  "models": {
    "embedding_model": "BAAI/bge-small-zh-v1.5",
    "llm_endpoint": "http://localhost:11434",
    "llm_model": "qwen2.5:1.5b"
  }
}
```

### è·¯ç”±ä¼˜åŒ–

```python
# é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–çš„è·¯ç”±ç¤ºä¾‹
module_examples = {
    "vdb": [
        "æŸ¥æ‰¾æ–‡æ¡£å†…å®¹", "æœç´¢èµ„æ–™", "å†å²å¯¹è¯", 
        "ç¬”è®°æ£€ç´¢", "çŸ¥è¯†æŸ¥è¯¢", "æ–‡çŒ®æœç´¢"
    ],
    "sql": [
        "é…ç½®å‚æ•°", "ç³»ç»Ÿè®¾ç½®", "APIé™åˆ¶", 
        "æ•°æ®åº“æŸ¥è¯¢", "è§„åˆ™é…ç½®", "å‚æ•°è®¾ç½®"
    ],
    "graph": [
        "äººå‘˜å…³ç³»", "ç»„ç»‡æ¶æ„", "åˆä½œä¼™ä¼´", 
        "ä¸Šä¸‹æ¸¸å…³ç³»", "çŸ¥è¯†å›¾è°±", "å…³ç³»ç½‘ç»œ"
    ]
}
```

## æ€§èƒ½ç›‘æ§

### èµ„æºç›‘æ§è„šæœ¬

```python
# monitor.py
import psutil
import time

def monitor_resources():
    while True:
        cpu = psutil.cpu_percent()
        memory = psutil.virtual_memory().percent
        print(f"CPU: {cpu}% | å†…å­˜: {memory}%")
        time.sleep(5)

if __name__ == "__main__":
    monitor_resources()
```

### æ€§èƒ½æµ‹è¯•

```python
# benchmark.py
import time
from cherry_plugin.plugin import CherryContextPlugin

def benchmark():
    plugin = CherryContextPlugin()
    
    test_queries = [
        "å¼ ä¸‰çš„åˆä½œä¼™ä¼´æœ‰å“ªäº›ï¼Ÿ",
        "APIæ¥å£é™åˆ¶æ˜¯å¤šå°‘ï¼Ÿ", 
        "æŸ¥æ‰¾Pythonæ•™ç¨‹æ–‡æ¡£"
    ]
    
    for query in test_queries:
        start = time.time()
        result = plugin.process_question(query)
        end = time.time()
        
        print(f"æŸ¥è¯¢: {query}")
        print(f"è·¯ç”±: {result['route']}")
        print(f"è€—æ—¶: {end-start:.2f}ç§’")
        print(f"ç»“æœ: {len(result['retrieved'])}æ¡")
        print("-" * 50)

if __name__ == "__main__":
    benchmark()
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Ollamaè¿æ¥å¤±è´¥**
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:11434/api/tags

# é‡å¯æœåŠ¡
pkill ollama
ollama serve
```

2. **å†…å­˜ä¸è¶³**
```python
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# å‡å°‘æ‰¹å¤„ç†å¤§å°
batch_size = 8
```

3. **ä¸­æ–‡è¯†åˆ«é—®é¢˜**
```python
# ä½¿ç”¨ä¸“é—¨çš„ä¸­æ–‡æ¨¡å‹
model = SentenceTransformer('shibing624/text2vec-base-chinese')
```

## ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### Dockeréƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY . .

RUN pip install -r requirements_mcp.txt

# ä¸‹è½½æ¨¡å‹
RUN python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('BAAI/bge-small-zh-v1.5')"

EXPOSE 8000
CMD ["python", "cherry_context_mcp_v2.py"]
```

```bash
# æ„å»ºå’Œè¿è¡Œ
docker build -t cherry-context .
docker run -p 8000:8000 -v ./data:/app/cherry_plugin/data cherry-context
```

### æœåŠ¡åŒ–éƒ¨ç½²

```bash
# systemdæœåŠ¡æ–‡ä»¶
sudo tee /etc/systemd/system/cherry-context.service << EOF
[Unit]
Description=Cherry Context Plugin
After=network.target

[Service]
Type=simple
User=cherry
WorkingDirectory=/opt/cherry_context_plugin
ExecStart=/opt/cherry_context_plugin/venv/bin/python cherry_context_mcp_v2.py
Restart=always

[Install]
WantedBy=multi-user.target
EOF

# å¯ç”¨æœåŠ¡
sudo systemctl enable cherry-context
sudo systemctl start cherry-context
```